# IoT Packet Verifier - Design

See [README](../README.md) for overview.

Data flow with AWS S3 elided:

```
HPR → PV → PS → CS
 ↑              /
  \____________/
```

where:

- HPR is [Helium Packet Router](https://github.com/helium/helium-packet-router/)
- PV is [this](..) component, the IoT Packet Verifier
- PS is the Payment System
  + follows the blockchain
  + credits Rewards to gateway owners' wallets for providing the network
  + debits Data Credits (DC) of OUI owners' wallets for use of the network
- CS is the Config Server associated with HPR

## Packet Verifier

- Extract metadata from Protobufs via S3 (read-only)
- Sum packet counters by gateway for Rewards
- Sum packet counters by OUI for debiting DC
- Write output as Protobufs via S3 (create & append only)
- Fetch from Config Server:
  + List of customer OUIs and their NetIDs

## Payment Server

- Consumes reports generated by PV
  + one S3 input file == one batch of txns on chain
- Follows blockchain and makes txns on chain:
  + Lookup wallets associated with gateway owners and OUI owners
  + credit Rewards to wallets associated with gateways
  + debit DC from wallets associated with OUIs
- Notify Config Server:
  + Disable routes when an OUI wallet has insufficient balance
  + Enable routes when an OUI wallet has sufficient balance
- Fetch from Config Server:
  + Map of OUI to list of NetIDs
  + DC rates for debiting customer wallets
  + Rewards rates for crediting gateway wallets

Note: only PS follows the chain (which keeps PV simple)

## PV Input Processing

- Sequence of S3 input is in approximate timeseries order
- Update tables by gateway, by OUI:
  + HashMap by gateway -> inc counter for Rewards
  + HashMap by OUI -> inc counter for debiting DC

## PV Output stream

- When each S3 input file ends, write output and reset counters
- Write small atomic blocks containing a header and body
  + because `file_sink.rs` rolls output file after 50MB or 15 minutes

## Dispatcher

- Dispatcher may be Tokio or separate processes-- TBD
  + Trade-off between async+locks vs let OS scheduler do the work
- Watch S3 for new files
- As implicit txn on local OS:
  + Download input file from S3 to local file system
  + Process input file
  + Mark input file on local file system for deletion
  + Push output file to S3
  + Delete marked file
  + Therefore, same node can pick-up where it left off; and
    workflow survives hard stop/start with minimal duplication;
    e.g., when using ephemeral storage
- One worker per S3 input file:
  + Accommodates high concurrency
  + Unlikely to fall behind
  + Cheap GC via `fork()`, `exec()` and `exit()`
    (however, S3 files will be capped at 50MiB before gzip thus small-ish)
